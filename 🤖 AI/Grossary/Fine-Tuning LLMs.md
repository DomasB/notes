The fine-tuning of a ML model is when you take a base model with frozen weights, add some new layers on top of the frozen layers, and train the new layers (fine-tune the model as a whole) using your own training data that is specific to the task you want to use your model for.

The fine-tuning of large language models (LLMs) is becoming increasingly impractical due to their rapidly-growing size. Larger LLMs need to be trained in parallel on a single GPU and the cost of fine-tuning.That said, there are a large number of open-source LLMs that can be downloaded and fine-tuned. Many people have downloaded [Facebookâ€™s LLaMA model](https://www.theverge.com/2023/3/8/23629362/meta-ai-language-model-llama-leak-online-misuse) and fine-tuned it for tasks, showing the potential for LLMs that can be fine-tuned on a single large GPU.


#fine-tuning #ml #nlp 